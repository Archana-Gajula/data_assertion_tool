{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ed9b21",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a65bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, array, when, array_remove, lit, size, array_contains\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbf2bf",
   "metadata": {},
   "source": [
    "specify the files needs to be compared and primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eaaa006",
   "metadata": {},
   "outputs": [],
   "source": [
    "    expected_file_path = '/Users/archanagajula/IdeaProjects/pyspark_data_assertion/data/expected_data.csv'\n",
    "    actual_file_path = '/Users/archanagajula/IdeaProjects/pyspark_data_assertion/data/actual_data.csv'\n",
    "    primary_key_column = 'vendor_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268690cd",
   "metadata": {},
   "source": [
    "start the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61119777",
   "metadata": {},
   "outputs": [],
   "source": [
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016763fc",
   "metadata": {},
   "source": [
    "read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6039df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    actual_df = spark.read.csv(actual_file_path, sep=',', header=True)\n",
    "    expected_df = spark.read.csv(expected_file_path, sep=',', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5dc7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of all records from expected: 7\n",
      "Distinct Count of records from expected: 7\n",
      "Count of all records from actual: 7\n",
      "Distinct Count of records from actual: 7\n"
     ]
    }
   ],
   "source": [
    "    print(\"Count of all records from expected:\", expected_df.count())\n",
    "    print(\"Distinct Count of records from expected:\", expected_df.distinct().count())\n",
    "    print(\"Count of all records from actual:\", actual_df.count())\n",
    "    print(\"Distinct Count of records from actual:\", actual_df.distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d09308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of records that are in both: 4\n"
     ]
    }
   ],
   "source": [
    "    common_records_df = expected_df.intersect(actual_df)\n",
    "    print(\"Count of records that are in both:\", common_records_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e8571c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    only_expected_df = expected_df.subtract(actual_df)\n",
    "\n",
    "    only_actual_df = actual_df.subtract(expected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "436ba9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of records that are only in expected: 3\n"
     ]
    }
   ],
   "source": [
    "    print('Count of records that are only in expected:',only_expected_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df86151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of records that are only in actual: 3\n"
     ]
    }
   ],
   "source": [
    "    print('Count of records that are only in actual:',only_actual_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "209b53bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some non common records from expected:\n",
      "+---------+-------------------+-------------------+---------------+-------------+------------+------------------+------------------+-------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|vendor_id|pickup_datetime    |dropoff_datetime   |passenger_count|trip_distance|rate_code_id|store_and_fwd_flag|pickup_location_id|dropoff_location_id|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+---------+-------------------+-------------------+---------------+-------------+------------+------------------+------------------+-------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|7        |2019-01-27 18:49:51|2019-01-27 19:49:51|1              |1.3          |1           |N                 |144               |45                 |2           |10.5       |0.0  |null   |null      |null        |null                 |null        |null                |\n",
      "+---------+-------------------+-------------------+---------------+-------------+------------+------------------+------------------+-------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    print(\"Some non common records from expected:\")\n",
    "    expected_non_matching_records = only_expected_df.join(only_actual_df, on=primary_key_column, how='left_anti').select(\n",
    "        only_expected_df[\"*\"])\n",
    "    expected_non_matching_records.orderBy(F.col(primary_key_column).asc()).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a7a640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some non common records from actual:\n",
      "+---------+-------------------+-------------------+---------------+-------------+------------+------------------+------------------+-------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|vendor_id|pickup_datetime    |dropoff_datetime   |passenger_count|trip_distance|rate_code_id|store_and_fwd_flag|pickup_location_id|dropoff_location_id|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+---------+-------------------+-------------------+---------------+-------------+------------+------------------+------------------+-------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|8        |2019-01-26 18:20:17|2019-01-26 18:39:27|1              |1.3          |1           |N                 |144               |45                 |2           |10.5       |0.0  |0.5    |0.0       |0.0         |0.3                  |11.3        |0.0                 |\n",
      "+---------+-------------------+-------------------+---------------+-------------+------------+------------------+------------------+-------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    print(\"Some non common records from actual:\")\n",
    "    actual_non_matching_records = only_actual_df.join(only_expected_df, on=primary_key_column, how='left_anti').select(\n",
    "        only_actual_df[\"*\"])\n",
    "    actual_non_matching_records.orderBy(F.col(primary_key_column).asc()).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd0cac",
   "metadata": {},
   "source": [
    "compare records column wise and adding non matching column names into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f159c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "    mismatch_columns = [when(expected_df[c] != actual_df[c], lit(c)).otherwise(\"\") for c in expected_df.columns]\n",
    "    select_exp = [col(primary_key_column), array_remove(array(*mismatch_columns), \"\").alias(\"mismatch_columns\")]\n",
    "    mismatch_columns_df = expected_df.join(actual_df,\n",
    "                                           on=primary_key_column, how='inner').select(select_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e454969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of records having mismatch: 2\n",
      "Count of records matching: 4\n"
     ]
    }
   ],
   "source": [
    "    print('Count of records having mismatch:', mismatch_columns_df.filter(size(\"mismatch_columns\") > 0).count())\n",
    "    print('Count of records matching:', mismatch_columns_df.filter(size(\"mismatch_columns\") == 0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c4fad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------------------+\n",
      "|vendor_id|mismatch_columns                |\n",
      "+---------+--------------------------------+\n",
      "|3        |[passenger_count, trip_distance]|\n",
      "|6        |[pickup_datetime]               |\n",
      "+---------+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    mismatch_columns_df.filter(size(\"mismatch_columns\") > 0).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
